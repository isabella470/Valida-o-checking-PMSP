import streamlit as st
import pandas as pd
import numpy as np
import io
import csv
from rapidfuzz import process, fuzz
from unidecode import unidecode
import re

# ==============================================================================
# 1. FUN√á√ïES DE LIMPEZA AVAN√áADA DE DADOS
# ==============================================================================

def pre_limpeza(nome):
    """Padroniza abrevia√ß√µes e termos comuns ANTES da normaliza√ß√£o principal."""
    nome = str(nome).lower()
    # A corre√ß√£o do NameError est√° aqui: a vari√°vel agora se chama 'substituicoes' nos dois lugares.
    substituicoes = {
        's.paulo': 'sao paulo',
        'sp': 'sao paulo',
        'rj': 'rio de janeiro',
        'r.': 'radio',
        # Adicione outras substitui√ß√µes que voc√™ identificar aqui
    }
    for antigo, novo in substituicoes.items():
        nome = re.sub(r'\b' + re.escape(antigo) + r'\b', novo, nome)
    return nome

def remover_ruido(nome):
    """Remove informa√ß√µes que mais atrapalham do que ajudam na compara√ß√£o."""
    nome = re.sub(r'\d+[\.,]\d+', '', nome)
    palavras_ruido = ['ltda', 's/a', 'eireli', 'radio', 'tv', 'jornal', 'emissora', 'rede', 'fm', 'am']
    for palavra in palavras_ruido:
        nome = re.sub(r'\b' + palavra + r'\b', '', nome)
    return re.sub(r'\s+', ' ', nome).strip()

def normalizar_nome_avancado(nome):
    """Pipeline completo de limpeza e normaliza√ß√£o de nomes."""
    if pd.isna(nome):
        return ""
    nome_limpo = pre_limpeza(nome)
    nome_limpo = remover_ruido(nome_limpo)
    nome_final = unidecode(nome_limpo)
    nome_final = re.sub(r'[^a-z0-9 ]', '', nome_final)
    nome_final = re.sub(r'\s+', ' ', nome_final).strip()
    return nome_final

# ==============================================================================
# 2. FUN√á√ïES DE LEITURA, MAPEAMENTO E COMPARA√á√ÉO
# ==============================================================================

def ler_csv(file):
    """L√™ um arquivo CSV, tentando detectar o separador."""
    file.seek(0)
    try:
        dialect = csv.Sniffer().sniff(file.read(1024).decode('utf-8'))
        sep = dialect.delimiter
    except (csv.Error, UnicodeDecodeError):
        sep = ';'
    file.seek(0)
    return pd.read_csv(file, sep=sep, encoding='utf-8')

@st.cache_data
def carregar_depara(caminho="depara.csv"):
    """Carrega e normaliza o arquivo De/Para."""
    try:
        df = pd.read_csv(caminho)
        df.columns = df.columns.str.strip().str.lower()
        df['veiculo_soudview'] = df['veiculo_soudview'].apply(normalizar_nome_avancado)
        df['veiculos boxnet'] = df['veiculos boxnet'].apply(normalizar_nome_avancado)
        return df
    except FileNotFoundError:
        st.error(f"Erro: O arquivo de mapeamento '{caminho}' n√£o foi encontrado.")
        return pd.DataFrame(columns=['veiculo_soudview', 'veiculos boxnet'])

def mapear_veiculo(nome, df_depara, veiculos_principais, limite_confianca):
    """Fun√ß√£o central de match, usando a normaliza√ß√£o avan√ßada."""
    nome_norm = normalizar_nome_avancado(nome)
    if not nome_norm:
        return "NOME VAZIO", None, "‚ö™ Vazio"

    encontrado = df_depara[df_depara['veiculo_soudview'] == nome_norm]
    if not encontrado.empty:
        return encontrado['veiculos boxnet'].values[0], 100, "‚úÖ De/Para"

    veiculos_principais_norm = [normalizar_nome_avancado(v) for v in veiculos_principais]
    if veiculos_principais_norm:
        melhor_checking, score_checking, _ = process.extractOne(nome_norm, veiculos_principais_norm, scorer=fuzz.WRatio)
        if score_checking >= limite_confianca:
            return melhor_checking, score_checking, "ü§ñ Fuzzy Checking"

    return "N√ÉO ENCONTRADO", None, "‚ùå N√£o encontrado"

def comparar_planilhas(df_soud, df_checking, df_depara, limite_confianca):
    """Orquestra todo o processo de compara√ß√£o."""
    veiculos_principais = df_checking['ve√≠culo boxnet'].dropna().unique().tolist()
    
    resultados = df_soud['veiculo_soudview'].apply(
        lambda x: mapear_veiculo(x, df_depara, veiculos_principais, limite_confianca)
    )
    df_soud['veiculo_mapeado'] = [r[0] for r in resultados]
    df_soud['score_similaridade'] = [r[1] for r in resultados]
    df_soud['tipo_match'] = [r[2] for r in resultados]
    
    df_soud_norm = df_soud.copy()
    df_checking_norm = df_checking.copy()
    
    df_soud_norm['data_merge'] = pd.to_datetime(df_soud_norm['data'], errors='coerce').dt.strftime('%Y-%m-%d')
    df_checking_norm['data_merge'] = pd.to_datetime(df_checking_norm['data veicula√ß√£o'], dayfirst=True, errors='coerce').dt.strftime('%Y-%m-%d')
    df_soud_norm['horario_merge'] = pd.to_datetime(df_soud_norm['horario'], errors='coerce').dt.strftime('%H:%M')
    df_checking_norm['horario_merge'] = pd.to_datetime(df_checking_norm['hora veicula√ß√£o'], errors='coerce').dt.strftime('%H:%M')
    
    df_soud_norm.fillna({'data_merge': '', 'horario_merge': ''}, inplace=True)
    df_checking_norm.fillna({'data_merge': '', 'horario_merge': ''}, inplace=True)
    
    df_checking_norm['veiculo_merge'] = df_checking_norm['ve√≠culo boxnet'].apply(normalizar_nome_avancado)
    
    relatorio = pd.merge(df_soud_norm, df_checking_norm, left_on=['veiculo_mapeado', 'data_merge', 'horario_merge'], right_on=['veiculo_merge', 'data_merge', 'horario_merge'], how='left', indicator=True)
    relatorio['status'] = np.where(relatorio['_merge'] == 'both', '‚úÖ Encontrado', '‚ùå N√£o Encontrado')
    
    colunas_finais = ['veiculo_soudview', 'comercial_soudview', 'data', 'horario', 'veiculo_mapeado', 'score_similaridade', 'tipo_match', 'status']
    colunas_existentes = [col for col in colunas_finais if col in relatorio.columns]
    
    return relatorio[colunas_existentes]

# ==============================================================================
# 3. INTERFACE DO STREAMLIT
# ==============================================================================

st.set_page_config(page_title="Validador de Checking", layout="wide") 
st.title("Painel de Valida√ß√£o de Checking üõ†Ô∏è")

st.sidebar.header("‚öôÔ∏è Controles de Match")
limite_confianca = st.sidebar.slider(
    "N√≠vel de Confian√ßa para Similaridade (%)",
    min_value=60, max_value=100, value=85, step=1,
    help="Define o qu√£o parecido um nome deve ser para dar 'match' autom√°tico. Se a pontua√ß√£o for menor, ser√° 'N√£o Encontrado'."
)

st.header("1. Carregue os Arquivos")
df_depara = carregar_depara("depara.csv")

col1, col2 = st.columns(2)
with col1:
    checking_file = st.file_uploader("Planilha Principal (Checking)", type=["csv", "xlsx", "xls"])
with col2:
    soud_file = st.file_uploader("Planilha Soudview", type=["xlsx", "xls"])

if st.button("‚ñ∂Ô∏è Iniciar Valida√ß√£o", use_container_width=True, type="primary"):
    if not checking_file or not soud_file or (df_depara is not None and df_depara.empty):
        st.warning("Por favor, carregue a Planilha Principal, a Planilha Soudview e verifique se o arquivo 'depara.csv' existe e n√£o est√° vazio.")
    else:
        try:
            from soudview import parse_soudview
            soud_file.seek(0)
            df_soud = parse_soudview(pd.read_excel(soud_file, header=None))
            df_soud.columns = df_soud.columns.str.strip().str.lower()

            if checking_file.name.endswith('.csv'):
                df_checking = ler_csv(checking_file)
            else:
                df_checking = pd.read_excel(checking_file)
            df_checking.columns = df_checking.columns.str.strip().str.lower()
            
            with st.spinner("Analisando... A nova limpeza avan√ßada pode levar um pouco mais de tempo."):
                relatorio_final = comparar_planilhas(df_soud, df_checking, df_depara, limite_confianca)

            st.header("2. Relat√≥rio da Compara√ß√£o")
            st.dataframe(relatorio_final)

            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                relatorio_final.to_excel(writer, index=False, sheet_name="Relatorio")
            st.download_button("üì• Baixar Relat√≥rio Final", output.getvalue(), "Relatorio_Final.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

            nao_encontrados = relatorio_final[relatorio_final['status'] == '‚ùå N√£o Encontrado']
            if not nao_encontrados.empty:
                st.header("3. Diagn√≥stico de Itens N√£o Encontrados ('Raio-X')")
                st.warning("Use esta an√°lise para encontrar os problemas e melhorar seu arquivo `depara.csv`.")
                
                veiculos_falharam = nao_encontrados['veiculo_soudview'].unique()
                veiculos_checking = df_checking['ve√≠culo boxnet'].dropna().unique()
                
                veiculos_checking_norm_map = {normalizar_nome_avancado(v): v for v in veiculos_checking}

                for veiculo in veiculos_falharam:
                    with st.expander(f"üîç An√°lise para: **{veiculo}**"):
                        nome_normalizado = normalizar_nome_avancado(veiculo)
                        st.write(f"Nome ap√≥s limpeza avan√ßada: `{nome_normalizado}`")
                        st.write("Abaixo est√£o os 5 candidatos mais pr√≥ximos da sua Planilha Principal (Checking):")
                        
                        candidatos = process.extract(
                            nome_normalizado, 
                            veiculos_checking_norm_map.keys(), 
                            scorer=fuzz.WRatio, 
                            limit=5
                        )
                        
                        if candidatos:
                            nomes_originais = [veiculos_checking_norm_map[c[0]] for c in candidatos]
                            scores = [round(c[1], 2) for c in candidatos]
                            df_candidatos = pd.DataFrame({
                                "Candidato na Planilha Principal": nomes_originais,
                                "Pontua√ß√£o de Similaridade (%)": scores
                            })
                            st.dataframe(df_candidatos, use_container_width=True)
                            st.info(f"**A√ß√£o recomendada:** Se um dos candidatos (ex: '{nomes_originais[0]}') estiver correto, adicione uma linha no seu `depara.csv` com '{veiculo}' na primeira coluna e '{nomes_originais[0]}' na segunda.")
                        else:
                            st.write("Nenhum candidato razo√°vel encontrado.")

        except ImportError:
            st.error("Erro Cr√≠tico: N√£o foi poss√≠vel encontrar a fun√ß√£o `parse_soudview`. Verifique se o arquivo `soudview.py` est√° na mesma pasta do seu app.")
        except Exception as e:
            st.error(f"Ocorreu um erro inesperado durante a execu√ß√£o: {e}")
