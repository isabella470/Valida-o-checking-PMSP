import streamlit as st
import pandas as pd
import numpy as np
import io
import re
import requests
from thefuzz import process, fuzz

try:
    from soudview import parse_soudview
except ImportError:
    st.error("ERRO: O arquivo 'soudview.py' n√£o foi encontrado.")
    st.stop()

# --- FUN√á√ïES GLOBAIS ---
def transformar_url_para_csv(url: str, aba: str = "Relat√≥rios"):
    # ... (c√≥digo da fun√ß√£o sem altera√ß√£o)
    try:
        match = re.search(r"/d/([a-zA-Z0-9-_]+)", url)
        if match:
            sheet_id = match.group(1)
            aba_codificada = requests.utils.quote(aba)
            return f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={aba_codificada}"
    except: return None

def comparar_planilhas(df_soud, df_checking):
    # Dicion√°rio de mapeamento. ESTA √â A PARTE QUE PRECISAMOS CORRIGIR.
    mapa_colunas = {
        'VEICULO_BOXNET': 'VEICULO', 
        'DATA_CONTRATACAO': 'DATA',
        'HORA_VEICULACAO': 'HORARIO', 
        'TITULO_PECA': 'COMERCIAL'
    }
    
    original_cols = df_checking.columns.tolist()
    df_checking.columns = df_checking.columns.str.strip().str.upper()
    df_checking.rename(columns=mapa_colunas, inplace=True)
    
    for col in ['VEICULO', 'DATA', 'HORARIO']:
        if col not in df_checking.columns:
            st.error(f"Erro Cr√≠tico: A coluna '{col}' n√£o foi encontrada na planilha principal ap√≥s o mapeamento. Colunas originais encontradas: {original_cols}")
            return pd.DataFrame()

    df_checking_sp = df_checking[df_checking['VEICULO'].str.contains("/S√ÉO PAULO", case=False, na=False)].copy()
    if df_checking_sp.empty:
        st.warning("Nenhum ve√≠culo de '/S√ÉO PAULO' foi encontrado na planilha principal para compara√ß√£o.")

    df_checking_sp['DATA'] = pd.to_datetime(df_checking_sp['DATA'], dayfirst=True, errors='coerce').dt.date
    df_checking_sp['HORARIO'] = pd.to_datetime(df_checking_sp['HORARIO'], errors='coerce').dt.time

    veiculos_soudview = df_soud['Veiculo_Soudview'].unique()
    veiculos_checking = df_checking_sp['VEICULO'].unique()
    mapa_veiculos = {}
    for veiculo_soud in veiculos_soudview:
        if pd.notna(veiculo_soud) and veiculos_checking.size > 0:
            match = process.extractOne(veiculo_soud, veiculos_checking, scorer=fuzz.token_set_ratio)
            if match and match[1] >= 80:
                mapa_veiculos[veiculo_soud] = match[0]
            else:
                mapa_veiculos[veiculo_soud] = "N√ÉO MAPEADO"
        else:
            mapa_veiculos[veiculo_soud] = "N√ÉO MAPEADO"
            
    df_soud['Veiculo_Mapeado'] = df_soud['Veiculo_Soudview'].map(mapa_veiculos)
    relatorio = pd.merge(df_soud, df_checking_sp, left_on=['Veiculo_Mapeado', 'Data', 'Horario'], right_on=['VEICULO', 'DATA', 'HORARIO'], how='left', indicator=True)
    relatorio['Status'] = np.where(relatorio['_merge'] == 'both', '‚úÖ J√° no Checking', '‚ùå N√£o encontrado')
    colunas_finais = ['Veiculo_Soudview', 'Comercial_Soudview', 'Data', 'Horario', 'Veiculo_Mapeado', 'Status']
    return relatorio[colunas_finais]

# --- LAYOUT DO STREAMLIT ---
st.set_page_config(page_title="Validador de Checking", layout="centered")
st.title("Painel de Valida√ß√£o de Checking üõ†Ô∏è")

# As abas foram removidas temporariamente para focar 100% em resolver o problema da Soudview.
# Depois que funcionar, n√≥s as adicionamos de volta em 1 minuto.
st.header("Valida√ß√£o Soudview (Foco na Resolu√ß√£o)")

link_planilha_checking = st.text_input("Passo 1: Cole o link da Planilha Principal (Checking)", key="soud_link")
soud_file = st.file_uploader("Passo 2: Fa√ßa upload da Planilha Soudview", type=["xlsx", "xls", "csv"], key="soud_file")
debug_mode = st.checkbox("üîç Ativar Modo Depura√ß√£o", value=True, key="debug_soud") # Deixei ativado por padr√£o

if st.button("‚ñ∂Ô∏è Iniciar Valida√ß√£o", use_container_width=True, key="btn_soud"):
    if link_planilha_checking and soud_file:
        with st.spinner("Analisando..."):
            df_raw_soud = pd.read_excel(soud_file, header=None)
            df_soud = parse_soudview(df_raw_soud)

            st.success(f"{len(df_soud)} veicula√ß√µes extra√≠das da Soudview!")
            
            url_csv = transformar_url_para_csv(link_planilha_checking)
            response = requests.get(url_csv)
            df_checking = pd.read_csv(io.StringIO(response.text))
            
            # --- SUPER DEPURA√á√ÉO ATIVADA ---
            if debug_mode:
                st.info("--- DEPURA√á√ÉO DA PLANILHA PRINCIPAL (CHECKING) ---")
                st.write("Abaixo est√£o as 5 primeiras linhas da sua planilha principal:")
                st.dataframe(df_checking.head())
                st.write("**E estes s√£o os nomes EXATOS das colunas que ela cont√©m:**")
                st.code(df_checking.columns.tolist())
                st.write("--- FIM DA DEPURA√á√ÉO ---")
            # --------------------------------

            if not df_soud.empty:
                relatorio_final = comparar_planilhas(df_soud, df_checking)
                
                st.subheader("Resultado da Compara√ß√£o")
                st.dataframe(relatorio_final)
                
                # ... (l√≥gica de download aqui) ...
